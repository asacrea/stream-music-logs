Transform: AWS::Serverless-2016-10-31
Description: This is a template to create ETL pipeline pattern with AWS Step Functions
Parameters:
  pS3BucketName:
    Type: String
    Description: Unique S3 bucket to create
    AllowedPattern: '[a-zA-Z][a-zA-Z0-9_-]*'
  pStageFolder:
    Type: String
    Description: Folder to store staging files
    Default: stage
  pSourceFolder:
    Type: String
    Description: Source Folder to upload raw json dataset to trigger the AWS Step
      functions
    Default: source
  pArchiveFolder:
    Type: String
    Description: Folder to store archived dataset
    Default: archive
  pErrorFolder:
    Type: String
    Description: Folder to store dataset for any error
    Default: error
  pEmailforNotification:
    Description: Valid email address to send success or error notification
    Type: String
Resources:
  S3CustomResource:
    Type: Custom::S3CustomResource
    Properties:
      ServiceToken:
        Fn::GetAtt:
        - LambdaFunctionS3Object
        - Arn
      the_bucket:
        Ref: S3Bucket
      dirs_to_create:
        Fn::Join:
        - ','
        - - Ref: pSourceFolder
          - Ref: pStageFolder
      file_prefix: glue/gluejob.py
      file_content:
        Fn::Sub: "import sys\nfrom awsglue.transforms import *\nfrom awsglue.utils\
          \ import getResolvedOptions\nfrom pyspark.context import SparkContext\n\
          from pyspark.sql.functions import col, to_date, date_format, substring,\
          \ from_unixtime\nfrom awsglue.context import GlueContext\nfrom awsglue.dynamicframe\
          \ import DynamicFrame\nfrom awsglue.job import Job\n\n\nargs = getResolvedOptions(sys.argv,\
          \ [\"JOB_NAME\"])\nsc = SparkContext()\nglueContext = GlueContext(sc)\n\
          spark = glueContext.spark_session\njob = Job(glueContext)\njob.init(args[\"\
          JOB_NAME\"], args)\n\n# Script generated for node S3 bucket\nmusic_table\
          \ = glueContext.create_dynamic_frame.from_catalog(\n    database=\"${GlueDB}\"\
          ,\n    table_name=\"${pSourceFolder}\",\n    #transformation_ctx=\"S3bucket_node1\"\
          ,\n)\n\n#music_table.printSchema()\n\n# Convert the int field to a date\
          \ field\ntransformed_date = ApplyMapping.apply(\n    frame=music_table,\n\
          \    mappings=[\n        (\"artist\", \"string\", \"artist\", \"string\"\
          ),\n        (\"song\", \"string\", \"song\", \"string\"),\n        (\"duration\"\
          , \"double\", \"duration\", \"double\"),\n        (\"ts\", \"long\", \"\
          ts\", \"long\"),\n        (\"sessionId\", \"int\", \"sessionId\", \"int\"\
          ),\n        (\"auth\", \"string\", \"auth\", \"string\"),\n        (\"level\"\
          , \"string\", \"level\", \"string\"),\n        (\"itemInSession\", \"int\"\
          , \"itemInSession\", \"int\"),\n        (\"city\", \"string\", \"city\"\
          , \"string\"),\n        (\"zip\", \"string\", \"zip\", \"string\"),\n  \
          \      (\"state\", \"string\", \"state\", \"string\"),\n        (\"userAgent\"\
          , \"string\", \"userAgent\", \"string\"),\n        (\"lon\", \"double\"\
          , \"lon\", \"double\"),\n        (\"lat\", \"double\", \"lat\", \"double\"\
          ),\n        (\"userId\", \"int\", \"userId\", \"int\"),\n        (\"lastName\"\
          , \"string\", \"lastName\", \"string\"),\n        (\"firstName\", \"string\"\
          , \"firstName\", \"string\"),\n        (\"gender\", \"string\", \"gender\"\
          , \"string\"),\n        (\"registration\", \"long\", \"registration\", \"\
          long\"),\n    ],\n    transformation_ctx=\"transformed_date\",\n)\n\n# Convert\
          \ the dynamic frame back to a data frame\nmusic_table_df = transformed_date.toDF()\n\
          \n#column_values = music_table_df.select(\"report_date\").show()\n\nmusic_table_df\
          \ = music_table_df.withColumn('report_date', to_date(from_unixtime(music_table_df['ts']\
          \ / 1000, 'yyyy-MM-dd'))) \\\n                              .withColumn('registration_date',\
          \ to_date(from_unixtime(music_table_df['registration'] / 1000, 'yyyy-MM-dd')))\
          \ \\\n                              .withColumn('year', date_format('report_date',\
          \ 'yyyy')) \\\n                              .withColumn('month', date_format('report_date',\
          \ 'MM')) \\\n                              .withColumn('day', date_format('report_date',\
          \ 'dd'))\n\n# Convert the data frame back to a dynamic frame\ndfy = DynamicFrame.fromDF(dataframe=music_table_df,\
          \ glue_ctx=glueContext, name=\"dfy\")\n\ndatasink = glueContext.write_dynamic_frame.from_options(\n\
          \    frame=dfy,\n    connection_type=\"s3\",\n    connection_options={\"\
          path\": \"s3://${pS3BucketName}/${pStageFolder}/\",\n                  \
          \      \"compression\": \"snappy\",\n                        \"partitionKeys\"\
          : [\"year\", \"month\", \"day\", \"state\", \"city\", \"level\", \"gender\"\
          ]},\n    format=\"parquet\",\n    transformation_ctx=\"datasink\"\n)\n\n\
          job.commit()\n"
  KinesisFirehoseDeliveryStream:
    Type: AWS::KinesisFirehose::DeliveryStream
    DependsOn:
    - S3CustomResource
    Properties:
      DeliveryStreamName: MusicDeliveryStream
      DeliveryStreamType: DirectPut
      S3DestinationConfiguration:
        RoleARN:
          Fn::GetAtt:
          - FirehoseRole
          - Arn
        BucketARN:
          Fn::GetAtt:
          - S3Bucket
          - Arn
        Prefix: ''
        BufferingHints:
          IntervalInSeconds: 300
          SizeInMBs: 5
        CompressionFormat: UNCOMPRESSED
  FirehoseRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service: firehose.amazonaws.com
          Action: sts:AssumeRole
      Policies:
      - PolicyName: FirehoseS3WriteAccess
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - s3:Get*
            - s3:Put*
            - s3:Delete*
            Resource:
            - Fn::Sub: arn:aws:s3:::${pS3BucketName}/*
  LambdaLayerParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name:
        Fn::Sub: ${AWS::StackName}_lambda_layer
      Type: String
      Value: NA
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      ManagedPolicyArns:
      - Ref: ManagedPolicyforlambda
      - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
  ManagedPolicyforlambda:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      Description: This is sample CFN template
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Sid: s3listaccess
          Effect: Allow
          Action:
          - s3:List*
          Resource:
            Fn::Sub: arn:aws:s3:::${pS3BucketName}
        - Sid: s3putaccess
          Effect: Allow
          Action:
          - s3:Get*
          - s3:Put*
          - s3:Delete*
          Resource:
          - Fn::Sub: arn:aws:s3:::${pS3BucketName}/*
        - Sid: s3deletebucket
          Effect: Allow
          Action:
          - s3:DeleteBucket
          Resource:
            Fn::Sub: arn:aws:s3:::${pS3BucketName}
        - Sid: SNStopicaccess
          Effect: Allow
          Action: sns:Publish
          Resource:
            Ref: SNSTopic
        - Sid: glueaccess
          Effect: Allow
          Action: glue:*
          Resource:
          - Fn::Sub: arn:aws:glue:${AWS::Region}:${AWS::AccountId}:database/${GlueDB}
          - Fn::Sub: arn:aws:glue:${AWS::Region}:${AWS::AccountId}:crawler/${CrawlPartitionedFile}
          - Fn::Sub: arn:aws:glue:${AWS::Region}:${AWS::AccountId}:crawler/${CrawlRawFile}
          - Fn::Sub: arn:aws:glue:${AWS::Region}:${AWS::AccountId}:table/${GlueDB}/*
          - Fn::Sub: arn:aws:glue:${AWS::Region}:${AWS::AccountId}:catalog
  StepFunctionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - states.amazonaws.com
          Action:
          - sts:AssumeRole
      ManagedPolicyArns:
      - Ref: ManagedPolicyforstepfunction
  ManagedPolicyforstepfunction:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      Description: This is the StepFunction policy definition
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Sid: s3listaccess
          Effect: Allow
          Action: lambda:InvokeFunction
          Resource:
          - Fn::GetAtt:
            - ArchiveFunction
            - Arn
          - Fn::GetAtt:
            - StartCrawlerFunction
            - Arn
          - Fn::GetAtt:
            - CrawlerStatusCheckFunction
            - Arn
        - Sid: glueaccess
          Effect: Allow
          Action:
          - glue:StartJobRun
          - glue:GetJobRun
          - glue:GetJobRuns
          - glue:BatchStopJobRun
          Resource: '*'
        - Sid: xrayaccess
          Effect: Allow
          Action:
          - xray:PutTraceSegments
          - xray:PutTelemetryRecords
          - xray:GetSamplingRules
          - xray:GetSamplingTargets
          Resource: '*'
        - Sid: snsaccess
          Effect: Allow
          Action:
          - sns:*
          Resource: '*'
  LambdaFunctionS3Object:
    Type: AWS::Serverless::Function
    Properties:
      Layers:
      - Ref: LambdaLayerCfn
      Description: Work with S3 Buckets!
      Handler: s3object.lambda_handler
      CodeUri: s3://aws-cloud-formation-artifacts/921bf2181f4aa74fe8bab838a8ce1d63
      Role:
        Fn::GetAtt:
        - LambdaRole
        - Arn
      Timeout: 360
      Runtime: python3.9
  SNSTopic:
    Type: AWS::SNS::Topic
    Properties:
      KmsMasterKeyId: alias/aws/sns
      Subscription:
      - Endpoint:
          Ref: pEmailforNotification
        Protocol: email
  S3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      VersioningConfiguration:
        Status: Enabled
      BucketName:
        Fn::Sub: ${pS3BucketName}
  ArchiveFunction:
    Type: AWS::Serverless::Function
    Properties:
      Role:
        Fn::GetAtt:
        - LambdaRole
        - Arn
      Handler: move_file.lambda_handler
      CodeUri: s3://aws-cloud-formation-artifacts/921bf2181f4aa74fe8bab838a8ce1d63
      Runtime: python3.9
      Timeout: 30
      Environment:
        Variables:
          archive_folder_name:
            Ref: pArchiveFolder
          error_folder_name:
            Ref: pErrorFolder
  StartCrawlerFunction:
    Type: AWS::Serverless::Function
    Properties:
      Role:
        Fn::GetAtt:
        - LambdaRole
        - Arn
      Handler: start_crawler.lambda_handler
      CodeUri: s3://aws-cloud-formation-artifacts/921bf2181f4aa74fe8bab838a8ce1d63
      Runtime: python3.9
      Timeout: 60
  CrawlerStatusCheckFunction:
    Type: AWS::Serverless::Function
    Properties:
      Role:
        Fn::GetAtt:
        - LambdaRole
        - Arn
      Handler: check_crawler.lambda_handler
      CodeUri: s3://aws-cloud-formation-artifacts/921bf2181f4aa74fe8bab838a8ce1d63
      Runtime: python3.9
      Timeout: 30
      Environment:
        Variables:
          RETRYLIMIT: 200
  LambdaLayerCfn:
    Type: AWS::Serverless::LayerVersion
    Properties:
      LayerName: cfnresource-lib
      Description: My layer
      ContentUri: s3://aws-cloud-formation-artifacts/a37284c62b678fbad21a92b0552820fc
      CompatibleRuntimes:
      - python3.9
      LicenseInfo: MIT
  GlueDB:
    Type: AWS::Glue::Database
    Properties:
      CatalogId:
        Ref: AWS::AccountId
      DatabaseInput:
        Description: Glue Database
  GlueRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - glue.amazonaws.com
          Action:
          - sts:AssumeRole
      Policies:
      - PolicyName: root
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Sid: s3listaccess
            Effect: Allow
            Action:
            - s3:List*
            Resource:
              Fn::Sub: arn:aws:s3:::${pS3BucketName}
          - Sid: s3putaccess
            Effect: Allow
            Action:
            - s3:Get*
            - s3:Put*
            - s3:Delete*
            Resource:
              Fn::Sub: arn:aws:s3:::${pS3BucketName}/*
          - Sid: glue
            Effect: Allow
            Action: glue:*
            Resource:
            - Fn::Sub: arn:aws:glue:${AWS::Region}:${AWS::AccountId}:database/${GlueDB}
            - Fn::Sub: arn:aws:glue:${AWS::Region}:${AWS::AccountId}:table/${GlueDB}/*
            - Fn::Sub: arn:aws:glue:${AWS::Region}:${AWS::AccountId}:catalog
          - Sid: glueTables
            Effect: Allow
            Action: glue:CreateTable
            Resource:
              Fn::Sub: arn:aws:glue:${AWS::Region}:${AWS::AccountId}:table/${GlueDB}/*
          - Sid: cwlog
            Effect: Allow
            Action: logs:*
            Resource:
            - Fn::Sub: arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws-glue/*
  GlueJob:
    Type: AWS::Glue::Job
    Properties:
      Command:
        Name: glueetl
        ScriptLocation:
          Fn::Sub: s3://${pS3BucketName}/glue/gluejob.py
      DefaultArguments:
        --enable-auto-scaling: 'true'
        --job-bookmark-option: job-bookmark-enable
      ExecutionProperty:
        MaxConcurrentRuns: 20
      MaxRetries: 0
      Role:
        Ref: GlueRole
      GlueVersion: '4.0'
      NumberOfWorkers: 10
      WorkerType: G.1X
  CrawlRawFile:
    Type: AWS::Glue::Crawler
    Properties:
      Role:
        Ref: GlueRole
      Description: Crawler to generate the schema of the raw file
      SchemaChangePolicy:
        UpdateBehavior: UPDATE_IN_DATABASE
        DeleteBehavior: DELETE_FROM_DATABASE
      DatabaseName:
        Ref: GlueDB
      Targets:
        S3Targets:
        - Path:
            Fn::Sub: s3://${pS3BucketName}/${pSourceFolder}
  CrawlPartitionedFile:
    Type: AWS::Glue::Crawler
    Properties:
      Role:
        Ref: GlueRole
      Description: Crawler to generate the schema of the partitioned file
      SchemaChangePolicy:
        UpdateBehavior: UPDATE_IN_DATABASE
        DeleteBehavior: DELETE_FROM_DATABASE
      DatabaseName:
        Ref: GlueDB
      Targets:
        S3Targets:
        - Path:
            Fn::Sub: s3://${pS3BucketName}/${pStageFolder}
  EventBridgeRoleStepFunction:
    Type: AWS::IAM::Role
    Properties:
      RoleName: EventBridgeRoleStepFunction
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service: events.amazonaws.com
          Action: sts:AssumeRole
      Policies:
      - PolicyName: StepFunctionPolicy
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - states:StartExecution
            Resource:
              Fn::GetAtt:
              - StepFunction
              - Arn
  MyEventBridgeStepFunctionsRule:
    Type: AWS::Events::Rule
    Properties:
      Name: MyEventBridgeStepFunctionsRule
      Description: EventBridge rule to execute Step Function
      ScheduleExpression: rate(10 minutes)
      State: ENABLED
      Targets:
      - Arn:
          Fn::GetAtt:
          - StepFunction
          - Arn
        Id: StartStepFunction
        RoleArn:
          Fn::GetAtt:
          - EventBridgeRoleStepFunction
          - Arn
  StepFunction:
    Type: AWS::StepFunctions::StateMachine
    Properties:
      TracingConfiguration:
        Enabled: true
      RoleArn:
        Fn::GetAtt:
        - StepFunctionRole
        - Arn
      DefinitionString:
        Fn::Sub: "{\n  \"Comment\": \"ETL Music Log Streming\",\n  \"StartAt\": \"\
          Start Crawler For Raw File\",\n  \"States\": {\n    \"Start Crawler For\
          \ Raw File\": {\n      \"Type\": \"Task\",\n      \"ResultPath\": \"$.taskresult\"\
          ,\n      \"ResultSelector\": {\n          \"cnt\": \"0\",\n          \"\
          crawler_name\": \"${CrawlRawFile}\"\n      },\n      \"Resource\": \"arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:${StartCrawlerFunction}\"\
          ,\n      \"Parameters\": {\n          \"Crawler_Name\": \"${CrawlRawFile}\"\
          \n      },\n      \"Retry\": [\n          {\n              \"ErrorEquals\"\
          : [\n                  \"CrawlerRunningException\"\n              ],\n \
          \             \"IntervalSeconds\": 10,\n              \"MaxAttempts\": 10,\n\
          \              \"BackoffRate\": 2\n          }\n      ],\n      \"Catch\"\
          : [\n          {\n              \"ErrorEquals\": [\n                  \"\
          CrawlerRunningException\"\n              ],\n              \"Comment\":\
          \ \"Crawler is running for long time\",\n              \"Next\": \"FAIL\
          \ - Move file to error folder\"\n          },\n          {\n           \
          \   \"ErrorEquals\": [\n                  \"States.ALL\"\n             \
          \ ],\n              \"Comment\": \"Error fall back\",\n              \"\
          ResultPath\": \"$.error-info\",\n              \"Next\": \"Handle Failure\"\
          \n          }\n      ],\n      \"Next\": \"Raw File Crawler Status Check\"\
          \n    },\n    \"Raw File Crawler Status Check\": {\n        \"Type\": \"\
          Task\",\n        \"InputPath\": \"$.taskresult\",\n        \"Resource\"\
          : \"arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:${CrawlerStatusCheckFunction}\"\
          ,\n        \"Next\": \"Raw File Crawler Finished?\",\n        \"ResultPath\"\
          : \"$.taskresult\"\n    },\n    \"Raw File Crawler Finished?\": {\n    \
          \    \"Type\": \"Choice\",\n        \"Choices\": [\n            {\n    \
          \            \"Or\": [\n                    {\n                        \"\
          Variable\": \"$.taskresult.Status\",\n                        \"StringEquals\"\
          : \"STOPPING\"\n                    },\n                    {\n        \
          \                \"Variable\": \"$.taskresult.Status\",\n              \
          \          \"StringEquals\": \"RUNNING\"\n                    }\n      \
          \          ],\n                \"Next\": \"Raw File Crawler Wait\"\n   \
          \         },\n            {\n                \"Variable\": \"$.taskresult.Status\"\
          ,\n                \"StringEquals\": \"READY\",\n                \"Next\"\
          : \"Run Glue Job\"\n            },\n            {\n                \"Variable\"\
          : \"$.taskresult.Status\",\n                \"StringEquals\": \"RETRYLIMITREACH\"\
          ,\n                \"Next\": \"Handle Failure\"\n            },\n      \
          \      {\n                \"Variable\": \"$.taskresult.Status\",\n     \
          \           \"StringEquals\": \"FAILED\",\n                \"Next\": \"\
          Handle Failure\"\n            }\n        ],\n        \"Default\": \"Handle\
          \ Failure\"\n    },\n    \"Raw File Crawler Wait\": {\n        \"Type\"\
          : \"Wait\",\n        \"Seconds\": 30,\n        \"Next\": \"Raw File Crawler\
          \ Status Check\"\n    },\n    \"Handle Failure\": {\n      \"Type\": \"\
          Pass\",\n      \"Parameters\": {\n        \"StateMachineName.$\": \"$$.StateMachine.Name\"\
          ,\n        \"ExecutionName.$\": \"$$.Execution.Name\",\n        \"ExecutionTime.$\"\
          : \"$$.Execution.StartTime\",\n        \"ErrorMessage\": \"An error ocurred\
          \ in the ETL Job\",\n        \"FailedTaskName.$\": \"$$.State.Name\"\n \
          \     },\n      \"ResultPath\": \"$.taskresult\",\n      \"Next\": \"FAIL\
          \ - Move file to error folder\"\n    },\n    \"FAIL - Move file to error\
          \ folder\": {\n        \"Type\": \"Task\",\n        \"Next\": \"Error Notification\"\
          ,\n        \"Resource\": \"arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:${ArchiveFunction}\"\
          \n    },\n    \"Error Notification\": {\n      \"Type\": \"Task\",\n   \
          \   \"Resource\": \"arn:aws:states:::aws-sdk:sns:publish\",\n      \"Parameters\"\
          : {\n        \"Message.$\": \"States.Format('Error: {}, StateMachine:{},\
          \ Name: {}, Time: {}, Task: {}', $.taskresult.ErrorMessage, $.taskresult.StateMachineName,\
          \ $.taskresult.ExecutionName, $.taskresult.ExecutionTime ,$.taskresult.FailedTaskName)\"\
          ,\n        \"TopicArn\": \"${SNSTopic}\"\n      },\n      \"Next\": \"Fail\"\
          \n    },\n    \"Run Glue Job\": {\n        \"Type\": \"Task\",\n       \
          \ \"Next\": \"Start Crawler For Partitioned File\",\n        \"ResultPath\"\
          : null,\n        \"Resource\": \"arn:aws:states:::glue:startJobRun.sync\"\
          ,\n        \"Parameters\": {\n            \"JobName\": \"${GlueJob}\"\n\
          \        },\n    \"Catch\": [\n            {\n                \"ErrorEquals\"\
          : [\n                    \"States.ALL\"\n                ],\n          \
          \      \"Comment\": \"Error fall back for glue job\",\n                \"\
          ResultPath\": \"$.error-info\",\n                \"Next\": \"Handle Failure\"\
          \n            }\n        ]\n    },\n    \"Start Crawler For Partitioned\
          \ File\": {\n        \"Type\": \"Task\",\n        \"ResultPath\": \"$.taskresult\"\
          ,\n        \"ResultSelector\": {\n            \"cnt\": \"0\",\n        \
          \    \"crawler_name\": \"${CrawlPartitionedFile}\"\n        },\n       \
          \ \"Resource\": \"arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:${StartCrawlerFunction}\"\
          ,\n        \"Parameters\": {\n            \"Crawler_Name\": \"${CrawlPartitionedFile}\"\
          \n        },\n        \"Retry\": [\n            {\n                \"ErrorEquals\"\
          : [\n                    \"CrawlerRunningException\"\n                ],\n\
          \                \"IntervalSeconds\": 10,\n                \"MaxAttempts\"\
          : 10,\n                \"BackoffRate\": 2\n            }\n        ],\n \
          \       \"Catch\": [\n            {\n                \"ErrorEquals\": [\n\
          \                    \"CrawlerRunningException\"\n                ],\n \
          \               \"Comment\": \"Crawler is running for long time\",\n   \
          \             \"Next\": \"Handle Failure\"\n            },\n           \
          \ {\n                \"ErrorEquals\": [\n                    \"States.ALL\"\
          \n                ],\n                \"Comment\": \"Error fall back\",\n\
          \                \"ResultPath\": \"$.error-info\",\n                \"Next\"\
          : \"Handle Failure\"\n            }\n        ],\n        \"Next\": \"Partitioned\
          \ File Crawler Status Check\"\n    },\n    \"Partitioned File Crawler Status\
          \ Check\": {\n        \"Type\": \"Task\",\n        \"InputPath\": \"$.taskresult\"\
          ,\n        \"Resource\": \"arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:${CrawlerStatusCheckFunction}\"\
          ,\n        \"Next\": \"Partitioned File Crawler Finished?\",\n        \"\
          ResultPath\": \"$.taskresult\"\n    },\n    \"Partitioned File Crawler Finished?\"\
          : {\n        \"Type\": \"Choice\",\n        \"Choices\": [\n           \
          \ {\n                \"Or\": [\n                    {\n                \
          \        \"Variable\": \"$.taskresult.Status\",\n                      \
          \  \"StringEquals\": \"STOPPING\"\n                    },\n            \
          \        {\n                        \"Variable\": \"$.taskresult.Status\"\
          ,\n                        \"StringEquals\": \"RUNNING\"\n             \
          \       }\n                ],\n                \"Next\": \"Partitioned File\
          \ Crawler Wait\"\n            },\n            {\n                \"Variable\"\
          : \"$.taskresult.Status\",\n                \"StringEquals\": \"READY\"\
          ,\n                \"Next\": \"Move file to archive\"\n            },\n\
          \            {\n                \"Variable\": \"$.taskresult.Status\",\n\
          \                \"StringEquals\": \"RETRYLIMITREACH\",\n              \
          \  \"Next\": \"Handle Failure\"\n            },\n            {\n       \
          \         \"Variable\": \"$.taskresult.Status\",\n                \"StringEquals\"\
          : \"FAILED\",\n                \"Next\": \"Handle Failure\"\n          \
          \  }\n        ],\n        \"Default\": \"Handle Failure\"\n    },\n    \"\
          Partitioned File Crawler Wait\": {\n        \"Type\": \"Wait\",\n      \
          \  \"Seconds\": 30,\n        \"Next\": \"Partitioned File Crawler Status\
          \ Check\"\n    },\n    \"Fail\": {\n        \"Type\": \"Fail\",\n      \
          \  \"Cause\": \"validation failed\",\n        \"Error\": \"ValidationError\"\
          \n    },\n    \"Move file to archive\": {\n        \"Type\": \"Task\",\n\
          \        \"Resource\": \"arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:${ArchiveFunction}\"\
          ,\n        \"Next\": \"Success Notification\"\n    },\n    \"Success Notification\"\
          : {\n        \"Type\": \"Task\",\n        \"Resource\": \"arn:aws:states:::aws-sdk:sns:publish\"\
          ,\n        \"Parameters\": {\n                \"Message.$\": \"$\",\n  \
          \              \"TopicArn\": \"${SNSTopic}\"\n        },\n        \"End\"\
          : true\n    }\n  }\n}\n"
Outputs:
  GlueDBOutput:
    Description: GlueDB Name
    Value:
      Ref: GlueDB
